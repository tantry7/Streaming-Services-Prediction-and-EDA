# -*- coding: utf-8 -*-
"""netflix.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13AKEQIT5uLmzI_9ZU1qHUnysSHZXFrEz
"""

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans, AffinityPropagation
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline
import warnings
warnings.filterwarnings("ignore")
import plotly as py
import plotly.graph_objs as go
import os 
from sklearn.linear_model import LinearRegression

netflix_data = pd.read_csv("/content/drive/MyDrive/Datasets-Streaming/netflix_titles.csv")

amazon_data = pd.read_csv("/content/drive/MyDrive/Datasets-Streaming/amazon_prime_titles.csv")

disney_data = pd.read_csv("/content/drive/MyDrive/Datasets-Streaming/disney_plus_titles.csv")

hulu_data = pd.read_csv("/content/drive/MyDrive/Datasets-Streaming/hulu_titles.csv")

netflix_data.head(5)



hulu_data.head(5)

"""Null Rate in coloumns """

for col in netflix_data.columns:
    null_rate = netflix_data[col].isna().sum()/np.shape(netflix_data)[0] *100
    if null_rate >0:
      print("{} null rate : {}%".format(col,round(null_rate,2)))

for col in amazon_data.columns:
    null_rate = amazon_data[col].isna().sum() / np.shape(amazon_data)[0] * 100 
    if null_rate > 0 :
        print("{} null rate: {}%".format(col,round(null_rate,2)))

for i in disney_data.columns:
    null_rate = disney_data[i].isna().sum() / len(disney_data) * 100 
    if null_rate > 0 :
        print("{} null rate: {}%".format(i,round(null_rate,2)))

for i in hulu_data.columns:
    null_rate = hulu_data[i].isna().sum() / len(hulu_data) * 100 
    if null_rate > 0 :
        print("{} null rate: {}%".format(i,round(null_rate,2)))

"""Dealing with missing Data"""



netflix_data['country'] = netflix_data['country'].fillna(netflix_data['country'].mode()[0])
netflix_data['cast'] = netflix_data['cast'].fillna("No data")
netflix_data['director'] = netflix_data['director'].fillna("No Data")

netflix_data.dropna(inplace=True)

netflix_data.drop_duplicates( inplace=True)

netflix_data.isnull().sum()

netflix_data.info()

amazon_data['country'] = amazon_data['country'].fillna(amazon_data['country'].mode()[0])
amazon_data['cast'] = amazon_data['cast'].fillna("No data")
amazon_data['director'] = amazon_data['director'].fillna("No Data")
amazon_data['date_added'] = amazon_data['date_added'].fillna("No Data")
amazon_data["rating"] = amazon_data["rating"].fillna("No Data")
amazon_data.dropna(how = "all",inplace=True)
amazon_data.drop_duplicates( inplace=True)
amazon_data.isnull().sum()

amazon_data.info()

disney_data['country'] = disney_data['country'].fillna(disney_data['country'].mode()[0])
disney_data['cast'] = disney_data['cast'].fillna("No Data")
disney_data['director'] = disney_data['director'].fillna("No Data")
disney_data['date_added'] = disney_data['date_added'].fillna(" No Data")
disney_data['rating'] = disney_data['rating'].fillna("No Data")
disney_data.dropna(how = "all",inplace=True)
disney_data.drop_duplicates( inplace=True)
disney_data.isnull().sum()

disney_data.info()

hulu_data['country'] = hulu_data['country'].fillna(hulu_data['country'].mode()[0])
hulu_data['cast'] = hulu_data['cast'].fillna("No Data")
hulu_data['director'] = hulu_data['director'].fillna("No Data")
hulu_data['date_added'] = hulu_data['date_added'].fillna(" No Data")
hulu_data['rating'] = hulu_data['rating'].fillna("No Data")
hulu_data['duration'] = hulu_data['duration'].fillna("No Data")
hulu_data['description'] = hulu_data['description'].fillna("No Data") 
hulu_data.dropna(how = "all",inplace=True)
hulu_data.drop_duplicates( inplace=True)
hulu_data.isnull().sum()

hulu_data

netflix_data['date_added'][10]

netflix_data['date_added'] = pd.to_datetime(netflix_data['date_added'])
netflix_data['month_added'] = netflix_data['date_added'].dt.month
netflix_data['month_name_added'] = netflix_data['date_added'].dt.month_name()
netflix_data['year_added'] = netflix_data['date_added'].dt.year

"""visualizing"""

sns.palplot(['#221f1f','#b20710','#e50914','#f5f5f1'])
plt.title("Netflix Brand pallete", loc = "left",fontfamily="serif",fontsize=15,y=1.2)
plt.show()

from datetime import datetime

tl_dates = [
    "1997\nFounded",
    "1998\nMail Service",
    "2003\nGoes Public",
    "2007\nStreaming service",
    "2016\nGoes Global",
    "2021\nNetflix & Chill"
]

tl_x = [1, 2, 4, 5.3, 8,9]

tl_sub_x = [1.5,3,5,6.5,7]


tl_sub_times = [
    "1998","2000","2006","2010","2012"
]

tl_text = [
    "Netflix.com launched",
    "Starts\nPersonal\nRecommendations","Billionth DVD Delivery","Canadian\nLaunch","UK Launch\n(my birthplace)"]



fig, ax = plt.subplots(figsize=(15, 4), constrained_layout=True)
ax.set_ylim(-2, 1.75)
ax.set_xlim(0, 10)


ax.axhline(0, xmin=0.1, xmax=0.9, c='#4a4a4a', zorder=1)


ax.scatter(tl_x, np.zeros(len(tl_x)), s=120, c='#4a4a4a', zorder=2)
ax.scatter(tl_x, np.zeros(len(tl_x)), s=30, c='#fafafa', zorder=3)
ax.scatter(tl_sub_x, np.zeros(len(tl_sub_x)), s=50, c='#4a4a4a',zorder=4)

for x, date in zip(tl_x, tl_dates):
    ax.text(x, -0.55, date, ha='center', 
            fontfamily='serif', fontweight='bold',
            color='#4a4a4a',fontsize=12)
    
levels = np.zeros(len(tl_sub_x))    
levels[::2] = 0.3
levels[1::2] = -0.3
markerline, stemline, baseline = ax.stem(tl_sub_x, levels, use_line_collection=True)    
plt.setp(baseline, zorder=0)
plt.setp(markerline, marker=',', color='#4a4a4a')
plt.setp(stemline, color='#4a4a4a')

for idx, x, time, txt in zip(range(1, len(tl_sub_x)+1), tl_sub_x, tl_sub_times, tl_text):
    ax.text(x, 1.3*(idx%2)-0.5, time, ha='center', 
            fontfamily='serif', fontweight='bold',
            color='#4a4a4a' if idx!=len(tl_sub_x) else '#b20710', fontsize=11)
    
    ax.text(x, 1.3*(idx%2)-0.6, txt, va='top', ha='center', 
        fontfamily='serif',color='#4a4a4a' if idx!=len(tl_sub_x) else '#b20710')



for spine in ["left", "top", "right", "bottom"]:
    ax.spines[spine].set_visible(False)

ax.set_xticks([]) 
ax.set_yticks([]) 

ax.set_title("Netflix through the years", fontweight="bold", fontfamily='serif', fontsize=16, color='#4a4a4a')
ax.text(2.4,1.57,"From DVD rentals to a global audience of over 150m people - is it time for Netflix to Chill?", fontfamily='serif', fontsize=12, color='#4a4a4a')

plt.show()

"""Group by Content"""

x = netflix_data.groupby(['type'])['type'].count()
y = len(netflix_data)
r =((x/y)).round(2)
mf_ratio = pd.DataFrame(r).T

fig, ax = plt.subplots(1,1,figsize=(6.5, 2.5))
ax.barh(mf_ratio.index, mf_ratio['Movie'], 
        color='#b20710', alpha=0.9, label='Male')
ax.barh(mf_ratio.index, mf_ratio['TV Show'], left=mf_ratio['Movie'], 
        color='#221f1f', alpha=0.9, label='Female')

ax.set_xlim(0, 1)
ax.set_xticks([])
ax.set_yticks([])


for i in mf_ratio.index:
    ax.annotate(f"{int(mf_ratio['Movie'][i]*100)}%", 
                   xy=(mf_ratio['Movie'][i]/2, i),
                   va = 'center', ha='center',fontsize=40, fontweight='light', fontfamily='serif',
                   color='white')

    ax.annotate("Movie", 
                   xy=(mf_ratio['Movie'][i]/2, -0.25),
                   va = 'center', ha='center',fontsize=15, fontweight='light', fontfamily='serif',
                   color='white')
    
    
for i in mf_ratio.index:
    ax.annotate(f"{int(mf_ratio['TV Show'][i]*100)}%", 
                   xy=(mf_ratio['Movie'][i]+mf_ratio['TV Show'][i]/2, i),
                   va = 'center', ha='center',fontsize=40, fontweight='light', fontfamily='serif',
                   color='white')
    ax.annotate("TV Show", 
                   xy=(mf_ratio['Movie'][i]+mf_ratio['TV Show'][i]/2, -0.25),
                   va = 'center', ha='center',fontsize=15, fontweight='light', fontfamily='serif',
                   color='white')






fig.text(0.125,1.03,'Movie & TV Show distribution', fontfamily='serif',fontsize=15, fontweight='bold')
fig.text(0.125,0.92,'We see vastly more movies than TV shows on Netflix.',fontfamily='serif',fontsize=12)  

for s in ['top', 'left', 'right', 'bottom']:
    ax.spines[s].set_visible(False)
ax.legend().set_visible(False)
plt.show()

netflix_data['count'] = 1
netflix_data['first_country'] = netflix_data['country'].apply(lambda x:x.split(",")[0])
netflix_data['first_country'].head()

ratings_ages = {
    'TV-PG': 'Older Kids',
    'TV-MA': 'Adults',
    'TV-Y7-FV': 'Older Kids',
    'TV-Y7': 'Older Kids',
    'TV-14': 'Teens',
    'R': 'Adults',
    'TV-Y': 'Kids',
    'NR': 'Adults',
    'PG-13': 'Teens',
    'TV-G': 'Kids',
    'PG': 'Older Kids',
    'G': 'Kids',
    'UR': 'Adults',
    'NC-17': 'Adults'
}
netflix_data['target_ages'] = netflix_data['rating'].replace(ratings_ages)

netflix_data['target_ages']

netflix_data['first_country'].replace('United States','USA',inplace = True)
netflix_data['first_country'].replace('United Kingdom','UK',inplace = True)
netflix_data['first_country'].replace('South Korea','S.Korea',inplace = True)

data = netflix_data.groupby('first_country')['count'].sum().sort_values(ascending=False)[:10]
color_map = ['#f5f5f1' for _ in range(10)]
color_map[0] = color_map[1] = color_map[2] = "#b20710"
fig, ax = plt.subplots(1,1,figsize=(12,6))
ax.bar(data.index,data,width=0.5,edgecolor="darkgray",linewidth=0.6,color=color_map)
for i in data.index:
  ax.annotate(f"{data[i]}",
              xy=(i,data[i]+150),
              va = "center",ha="center",fontweight="light",fontfamily="serif")
  
for s in ['top','left','right']:
  ax.spines[s].set_visible(False)

ax.set_xticklabels(data.index, fontfamily = 'serif', rotation=0)
fig.text(0.09,1,'Top 10 countries on Netflix',fontsize = 15, fontweight = "bold",fontfamily="serif")
fig.text(0.09,0.95,"The three most frequent countries have been highlited.")
grid_y_ticks = np.arange(0,4000,500)
ax.set_yticks(grid_y_ticks)
ax.set_axisbelow(True)
plt.axhline(y=0,color="black",linewidth=1.3,alpha=0.7)
ax.tick_params(axis="both",which="major",labelsize=12)
import matplotlib.lines as lines 
l1 = lines.Line2D([1,1],[0,1],transform=fig.transFigure,figure=fig,color='black',lw=0.2)
fig.lines.extend([l1])
plt.show()

country_order = netflix_data['first_country'].value_counts()[:11].index
data_q2q3 = netflix_data[['type', 'first_country']].groupby('first_country')['type'].value_counts().unstack().loc[country_order]
data_q2q3['sum'] = data_q2q3.sum(axis=1)
data_q2q3_ratio = (data_q2q3.T / data_q2q3['sum']).T[['Movie', 'TV Show']].sort_values(by='Movie',ascending=False)[::-1]
fig, ax = plt.subplots(1,1,figsize=(15, 8),)

ax.barh(data_q2q3_ratio.index, data_q2q3_ratio['Movie'], 
        color='#b20710', alpha=0.8, label='Movie')
ax.barh(data_q2q3_ratio.index, data_q2q3_ratio['TV Show'], left=data_q2q3_ratio['Movie'], 
        color='#221f1f', alpha=0.8, label='TV Show')


ax.set_xlim(0, 1)
ax.set_xticks([])
ax.set_yticklabels(data_q2q3_ratio.index, fontfamily='serif', fontsize=11)

# male percentage
for i in data_q2q3_ratio.index:
    ax.annotate(f"{data_q2q3_ratio['Movie'][i]*100:.3}%", 
                   xy=(data_q2q3_ratio['Movie'][i]/2, i),
                   va = 'center', ha='center',fontsize=12, fontweight='light', fontfamily='serif',
                   color='white')

for i in data_q2q3_ratio.index:
    ax.annotate(f"{data_q2q3_ratio['TV Show'][i]*100:.3}%", 
                   xy=(data_q2q3_ratio['Movie'][i]+data_q2q3_ratio['TV Show'][i]/2, i),
                   va = 'center', ha='center',fontsize=12, fontweight='light', fontfamily='serif',
                   color='white')
    

fig.text(0.13, 0.93, 'Top 10 countries Movie & TV Show split', fontsize=15, fontweight='bold', fontfamily='serif')   
fig.text(0.131, 0.89, 'Percent Stacked Bar Chart', fontsize=12,fontfamily='serif')   

for s in ['top', 'left', 'right', 'bottom']:
    ax.spines[s].set_visible(False)
    

fig.text(0.75,0.9,"Movie", fontweight="bold", fontfamily='serif', fontsize=15, color='#b20710')
fig.text(0.81,0.9,"|", fontweight="bold", fontfamily='serif', fontsize=15, color='black')
fig.text(0.82,0.9,"TV Show", fontweight="bold", fontfamily='serif', fontsize=15, color='#221f1f')





import matplotlib.lines as lines
l1 = lines.Line2D([1, 1], [0, 1], transform=fig.transFigure, figure=fig,color='black',lw=0.2)
fig.lines.extend([l1])




ax.tick_params(axis='both', which='major', labelsize=12)
ax.tick_params(axis=u'both', which=u'both',length=0)

plt.show()

order = pd.DataFrame(netflix_data.groupby('rating')['count'].sum().sort_values(ascending=False).reset_index())
rating_order = list(order['rating'])

fig, ax = plt.subplots(1, 1, figsize=(12, 6))
color = ["#b20710", "#221f1f"]

for i, mtv in enumerate(netflix_data['type'].value_counts().index):
    mtv_rel = netflix_data[netflix_data['type']==mtv]['year_added'].value_counts().sort_index()
    ax.plot(mtv_rel.index, mtv_rel, color=color[i], label=mtv)
    ax.fill_between(mtv_rel.index, 0, mtv_rel, color=color[i], alpha=0.9)
    
ax.yaxis.tick_right()
    
ax.axhline(y = 0, color = 'black', linewidth = 1.3, alpha = .7)

#ax.set_ylim(0, 50)
#ax.legend(loc='upper left')
for s in ['top', 'right','bottom','left']:
    ax.spines[s].set_visible(False)

ax.grid(False)

ax.set_xlim(2008,2020)
plt.xticks(np.arange(2008, 2021, 1))


fig.text(0.13,0.2,"Movie", fontweight="bold", fontfamily='serif', fontsize=15, color='#b20710')
fig.text(0.19,0.2,"|", fontweight="bold", fontfamily='serif', fontsize=15, color='black')
fig.text(0.2,0.2,"TV Show", fontweight="bold", fontfamily='serif', fontsize=15, color='#221f1f')

ax.tick_params(axis=u'both', which=u'both',length=0)

plt.show()

"""MOVIE GENRES

"""

from sklearn.preprocessing import MultiLabelBinarizer
import matplotlib.colors
cmap = matplotlib.colors.LinearSegmentedColormap

# Genres
from sklearn.preprocessing import MultiLabelBinarizer 

import matplotlib.colors
cmap = matplotlib.colors.LinearSegmentedColormap.from_list("", ['#221f1f', '#b20710','#f5f5f1'])
def genre_heatmap(df, title):
    df['genre'] = df['listed_in'].apply(lambda x :  x.replace(' ,',',').replace(', ',',').split(',')) 
    Types = []
    for i in df['genre']: Types += i
    Types = set(Types)
    print("There are {} types in the Netflix {} Dataset".format(len(Types),title))    
    test = df['genre']
    mlb = MultiLabelBinarizer()
    res = pd.DataFrame(mlb.fit_transform(test), columns=mlb.classes_, index=test.index)
    corr = res.corr()
    mask = np.zeros_like(corr, dtype=np.bool)
    mask[np.triu_indices_from(mask)] = True
    fig, ax = plt.subplots(figsize=(10, 7))
    fig.text(.54,.88,'Genre correlation', fontfamily='serif',fontweight='bold',fontsize=15)
    fig.text(.75,.665,
            '''
             It is interesting that Independant Movies
             tend to be Dramas. 
             
             Another observation is that 
             Internatinal Movies are rarely
             in the Children's genre.
             ''', fontfamily='serif',fontsize=12,ha='right')
    pl = sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, vmin=-.3, center=0, square=True, linewidths=2.5)
    plt.show()

us_ind = netflix_data[(netflix_data['first_country'] == 'USA') | (netflix_data['first_country'] == 'India' )]
data_sub = netflix_data.groupby('first_country')['year_added'].value_counts().unstack().fillna(0).loc[['USA','India']].cumsum(axis=0).T

fig, ax = plt.subplots(1, 1, figsize=(12, 6))
color = ['#221f1f', '#b20710','#f5f5f1']

for i, hs in enumerate(us_ind['first_country'].value_counts().index):
    hs_built = us_ind[us_ind['first_country']==hs]['year_added'].value_counts().sort_index()
    ax.plot(hs_built.index, hs_built, color=color[i], label=hs)
    ax.fill_between(hs_built.index, 0, hs_built, color=color[i], label=hs)
    

ax.set_ylim(0, 1000)
for s in ['top', 'right']:
    ax.spines[s].set_visible(False)

ax.yaxis.tick_right()
ax.axhline(y = 0, color = 'black', linewidth = 1.3, alpha = .4)

for s in ['top', 'right','bottom','left']:
    ax.spines[s].set_visible(False)

ax.grid(False)
ax.set_xticklabels(data_sub.index, fontfamily='serif', rotation=0)
ax.margins(x=0) # remove white spaces next to margins

ax.set_xlim(2008,2020)
plt.xticks(np.arange(2008, 2021, 1))
fig.text(0.13,0.15,"India", fontweight="bold", fontfamily='serif', fontsize=15, color='#b20710')
fig.text(0.188,0.15,"|", fontweight="bold", fontfamily='serif', fontsize=15, color='black')
fig.text(0.198,0.15,"USA", fontweight="bold", fontfamily='serif', fontsize=15, color='#221f1f')
ax.tick_params(axis=u'both', which=u'both',length=0)
plt.show()

data_sub

from wordcloud import WordCloud
import random
from PIL import Image
import matplotlib

# Custom colour map based on Netflix palette
cmap = matplotlib.colors.LinearSegmentedColormap.from_list("", ['#221f1f', '#b20710'])

text = str(list(netflix_data['title'])).replace(',', '').replace('[', '').replace("'", '').replace(']', '').replace('.', '')

mask = np.array(Image.open('/content/drive/MyDrive/Datasets-Streaming/netflix_data/7-79068_netflix-n-logo-transparent-hd-png-download.png'))

wordcloud = WordCloud(background_color = 'white', width = 500,  height = 200,colormap=cmap, max_words = 150, mask = mask).generate(text)

plt.figure( figsize=(5,5))
plt.imshow(wordcloud, interpolation = 'bilinear')
plt.axis('off')
plt.tight_layout(pad=0)
plt.show()

from sklearn.feature_extraction.text import TfidfVectorizer
#removing stopwords
tfidf = TfidfVectorizer(stop_words='english')

#Replace NaN with an empty string
netflix_data['description'] = netflix_data['description'].fillna('')

#Construct the required TF-IDF matrix by fitting and transforming the data
tfidf_matrix = tfidf.fit_transform(netflix_data['description'])
tfidfg_matrix = tfidf.fit_transform(netflix_data['listed_in'])

#Output the shape of tfidf_matrix
tfidf_matrix.shape,tfidfg_matrix.shape

# Import linear_kernel
from sklearn.metrics.pairwise import linear_kernel

# Compute the cosine similarity matrix
cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)
indices = pd.Series(netflix_data.index, index=netflix_data['title']).drop_duplicates()



indices["zombieland"]



def get_recommendations_desc(title, cosine_sim=cosine_sim):
    idx = indices[title]

    # Get the pairwsie similarity scores of all movies with that movie
    sim_scores = list(enumerate(cosine_sim[idx]))

    # Sort the movies based on the similarity scores
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)

    # Get the scores of the 10 most similar movies
    sim_scores = sim_scores[1:11]
    # Get the movie indices
    movie_indices = [i[0] for i in sim_scores]

    # Return the top 10 most similar movies
    return netflix_data['title'].iloc[movie_indices]

get_recommendations_desc('kota factory',cosine_sim)

def get_recommendations_genre(title, cosine_sim=cosine_sim_genre):
    idx = indicies_genre[title]

    # Get the pairwsie similarity scores of all movies with that movie
    sim_scores = list(enumerate(cosine_sim_genre[idx]))

    # Sort the movies based on the similarity scores
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)

    # Get the scores of the 10 most similar movies
    sim_scores = sim_scores[1:11]

    # Get the movie indices
    movie_indices = [i[0] for i in sim_scores]

    # Return the top 10 most similar movies
    return netflix_data['title'].iloc[movie_indices]

get_recommendations_genre("kota factory",cosine_sim_genre)

books=pd.read_csv('/content/drive/MyDrive/Datasets-Streaming/netflix_data/books.csv')
books['original_title']=books['original_title'].str.lower()
x=netflix_data
x['title']=x['title'].str.lower()
t=x.merge(books, left_on='title', right_on='original_title', how="inner")

import plotly.graph_objects as go

labels = ['Shows from books','Shows not from books']
values = [248,6234]

fig = go.Figure(data=[go.Pie(labels=labels, values=values)])
fig.show()

